# Cakto Split Payment Challenge

ImplementaÃ§Ã£o de um mÃ³dulo de **Split Payments** em Django REST Framework, atendendo aos requisitos de escalabilidade, auditoria e observabilidade descritos no desafio.

---

## ğŸ“¦ Stack Utilizada

- **Django 5 + Django REST Framework** â†’ API REST e modelo de dados.
- **PostgreSQL** â†’ banco relacional com integridade financeira.
- **pytest + pytest-django** â†’ testes unitÃ¡rios e de integraÃ§Ã£o.
- **Prometheus Client** â†’ mÃ©tricas de observabilidade.
- **Docker + docker-compose** â†’ containerizaÃ§Ã£o do ambiente.

---

## ğŸš€ Como Rodar o Projeto

### PrÃ©-requisitos

- Python 3.13+ (ou superior)
- Docker e Docker Compose

### Rodando localmente (sem Docker)

1. Clone o repositÃ³rio:

   ```bash
   git clone https://github.com/lucascbenedet/canto-split-payment-challenge.git
   cd cakto-split-payment-challenge
   ```

2. Crie o ambiente virtual e instale dependÃªncias:

   ```bash
   python -m venv venv
   source venv/bin/activate
   pip install poetry
   poetry install
   ```

3. Configure o arquivo .env com as credenciais do banco de dados.

4. Rode as migraÃ§Ãµes:

   ```bash
   python manage.py migrate
   ```

5. Crie um super usuÃ¡rio:

   ```bash
   python manage.py createsuperuser
   ```

6. Suba o servidor:

   ```bash
   python manage.py runserver
   ```

---

### Rodando com Docker

1. Suba os containers:

   ```bash
   docker-compose up --build
   ```

2. Acesse:

   - Admin: `http://localhost:8000/admin/`
   - API: `http://localhost:8000/api/v1/`
   - DocumentaÃ§Ã£o: `http://localhost:8000/api/schema/swagger-ui/`

---

### Requisitos de funcionamento

1. Criar um produto:

   - Acesse o endpoint para criar um produto utilizando autorizaÃ§Ã£o bÃ¡sica com usuÃ¡rio e senha do superuser criado.

2. Criar regras de splits:
   - Ã‰ necessÃ¡rio que haja um produto previamente criado para vincular Ã  um split.
   - Sempre que um produto Ã© criado, uma feature flag Ã© criada na tabela config para ele. Para desativar a configuraÃ§Ã£o pra um produto especÃ­fico Ã© necessÃ¡rio entrar no django admin e desativar a flag.
3. Superuser:

   - O username e password do superuser criado estÃ£o no arquivo `.env` para local e `.env.docker` para docker. Por padrÃ£o o superuser Ã© criado com o username `cakto` e senha `123`.

## ğŸ§ª Testes

### UnitÃ¡rios e IntegraÃ§Ã£o

Os testes cobrem:

- ServiÃ§o de criaÃ§Ã£o de splits (`SplitService`).
- API `POST /api/v1/splits/`.
- ValidaÃ§Ãµes de negÃ³cio (percentuais, owner do produto, split duplicado).
- Fluxos felizes e de erro.

Rodando testes localmente:

```bash
pytest
```

Rodando testes dentro do container:

```bash
docker-compose exec web pytest
```

---

## ğŸ“Š DecisÃµes TÃ©cnicas

### Arquitetura

- **MonÃ³lito modular em Django**: escolhido pelo prazo de MVP (6 semanas) e compatibilidade com stack existente. Evita overhead de microsserviÃ§o, mas mantÃ©m separaÃ§Ã£o em mÃ³dulo (`split_rules`).
- **ConsistÃªncia**: transaÃ§Ãµes atÃ´micas garantem que split e regras sejam criados juntos ou revertidos em caso de erro.
- **Event sourcing**: nÃ£o implementado no MVP, mas a tabela `Rules` atua como histÃ³rico auditÃ¡vel.
- **Deploy**: pensado para ser canÃ¡rio (sem downtime) em Docker/K8s.
- **Escalabilidade**: PostgreSQL com Ã­ndices (`product_id`, `split_id`) e possibilidade de particionamento em `rules`.

### Resumo descritivo

- O event sourcing nÃ£o foi implementado devido ao tempo de entrega e equipe, porÃ©m a maneira como o mÃ³dulo foi criado permite o histÃ³rico de todas as configuraÃ§Ãµes. AlÃ©m disso, facilmente poderia ser integrado um banco de dados NoSQL para escrita dos eventos e a aplicaÃ§Ã£o de um sistema de mensageria que seria responsÃ¡vel por sincronizar os eventos com o banco de dados relacional que jÃ¡ foi estruturado pensando nessa abordagem futura.
- Foi implementado uma tabela de configuraÃ§Ãµes para armazenar as features flags, assim a funcionalidade pode ser disponibilizada para produtos especÃ­ficos evitando quebra do sistema em produÃ§Ã£o.
- A tabela `Split` foi criada para armazenar as configuraÃ§Ãµes de cada split, sendo que apenas um split poderia estar ativo por produto. Dessa forma, a validaÃ§Ã£o Ã© feita pelo status do split, o que faz com que todas as regras criadas nunca sejam sobrescritas.
- O mÃ³dulo de payment representa o fluxo atual do sistema onde o pagamento Ã© processado apenas para o criador do produto. Com o mÃ³dulo de splits, a configuraÃ§Ã£o do PaymentProcessor foi muito pouco refatorada, apenas tendo que verificar se, para o produto do pedido a configuraÃ§Ã£o de splits estÃ¡ habilitada e se existem regras ativas. Caso existam, o fluxo de pagamento seria feito baseado em cada regra.
- Para representar o fluxo de pagamento foram criadas classes de implementaÃ§Ã£o para processar pagamento em Pix, transfÃªrencia bancÃ¡ria ou qualquer outro mÃ©todo de pagamento que for necessÃ¡rio. Dessa forma, para cada regra de split o pagamento seria redirecionado para a classe de pagamento especÃ­fica responsÃ¡vel por Ã quele mÃ©todo de pagamento.
- NÃ£o foi implementado fila de tarefas assÃ­ncronas, mas para a entrega do MVP seria necessÃ¡rio que cada regra de pagamento seja processada como uma tarefa assÃ­ncrona distinta, para que o sistema nÃ£o seja bloqueado.
- Foram desenvolvidos testes unitÃ¡rios e de integraÃ§Ã£o em cima da classe `SplitSerivce` para garantir a qualidade do cÃ³digo e a funcionalidade do mÃ³dulo de splits.
- TambÃ©m foi desenvolvido mÃ©tricas e log para a observabilidade que podem ser facilmente incorporadas ao service e posteriormente integradas com algum sistema de monitoramento como Grafana.
- Todas as validaÃ§Ãµes de um split estÃ£o dentro do service, concentradas em um sÃ³ lugar, o que facilita a manutenÃ§Ã£o e a adiÃ§Ã£o de novas validaÃ§Ãµes caso necessÃ¡rio.

### Banco de Dados

- **Tabela `Split`** â†’ configuraÃ§Ã£o ativa por produto.
- **Tabela `Rules`** â†’ histÃ³rico detalhado de todas as regras.
- **Constraints**:

  - Apenas 1 split ativo por produto.
  - Soma de regras deve dar 100%.
  - `CHECK` em valores invÃ¡lidos.

- **Auditoria embutida**: `created_at`, `updated_at`.

---

## ğŸ“Š Observabilidade

### Logs

- Configurados no `settings.py`, enviados para **stdout** (coletado em Docker/K8s).
- O mÃ³dulo se adaptaria ao padrÃ£o de logs definidos no projeto principal.
- Bastaria configurar o caminho para um sistema de log externo como DataDog se necessÃ¡rio.
- Exemplo:

  ```json
  {
    "time": "2025-08-31T14:00:00",
    "level": "INFO",
    "logger": "split-payments",
    "message": "Split created"
  }
  ```

### MÃ©tricas Prometheus

Expostas em `/metrics` via `prometheus_client`.

- **Counters**:

  - `splits_created_total{product_id}` â†’ total de splits criados.
  - `splits_failed_total{reason}` â†’ falhas de criaÃ§Ã£o.
  - `split_anomalies_total{type}` â†’ inconsistÃªncias detectadas.

- **Histogram**:

  - `split_latency_seconds` â†’ latÃªncia do `SplitService`.

### Thresholds sugeridos

- `rate(splits_failed_total[5m]) > 5` â†’ alerta de falha.
- `histogram_quantile(0.95, split_latency_seconds) > 0.5` â†’ latÃªncia p95 acima de 500ms.
- `split_anomalies_total > 0` â†’ incidente crÃ­tico.

---

## ğŸ“Š Endpoints Principais

### Criar split

`POST /api/v1/splits/`

```json
{
  "product": "uuid-produto",
  "effective_date": "2025-01-01T00:00:00Z",
  "rules": [
    {
      "recipient_id": "user_creator",
      "type": "percentage",
      "value": 65,
      "payment_method": "bank",
      "account_info": { "bank": "001", "account": "12345-6" }
    },
    {
      "recipient_id": "user_partner",
      "type": "percentage",
      "value": 35,
      "payment_method": "pix",
      "account_info": { "pix_key": "partner@email.com" }
    }
  ]
}
```

### Respostas

- `201 Created` â†’ split criado.
- `400 Bad Request` â†’ validaÃ§Ã£o falhou (ex: soma â‰  100%).
- `401 Unauthorized` â†’ usuÃ¡rio nÃ£o autenticado.
- `403 Forbidden` â†’ usuÃ¡rio nÃ£o Ã© dono do produto.

### Criar produto

`POST /api/v1/products/`

```json
{
  "name": "Teste",
  "base_value": 100
}
```

### Listar produtos de um usuÃ¡rio

`GET /api/v1/products/`

### Recuperar um produto por id

`GET /api/v1/products/{product_id}/`

---

## ğŸ“Œ PrÃ³ximos Passos (evoluÃ§Ã£o real)

- Event sourcing com Kafka para auditoria externa.
- Dashboards Grafana para mÃ©tricas crÃ­ticas.

---
